{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID DOCUMENT_ID DOCUMENT_TYPE FILING_DATE          MODIFIED_AT  \\\n",
      "0   5240613   161068824            AR  2020-04-27  2021-07-01 06:55:58   \n",
      "1   5240613   161068824            AR  2020-04-27  2021-07-01 06:55:58   \n",
      "2   5240956   161070889            AR  2020-12-31  2021-07-01 06:55:58   \n",
      "3   5240976   161071121            AR  2020-12-31  2021-07-01 06:55:58   \n",
      "4   5241763   161091228            AR  2020-12-31  2021-07-01 06:56:03   \n",
      "5   5241763   161091228            AR  2020-12-31  2021-07-01 06:56:03   \n",
      "6   5241763   161091228            AR  2020-12-31  2021-07-01 06:56:03   \n",
      "7   5241763   161091228            AR  2020-12-31  2021-07-01 06:56:03   \n",
      "8   5242219     3252233            AR  2021-06-26  2021-07-04 00:49:47   \n",
      "9   5242348   142726274            AR  2021-06-26  2021-07-04 00:49:46   \n",
      "10  5242456      272384            AR  2021-06-26  2021-07-04 00:49:37   \n",
      "11  5242459     3268389            AR  2021-06-26  2021-07-04 00:49:37   \n",
      "\n",
      "                             DETAIL_JSON.company_name  \\\n",
      "0   AIM Tax-Exempt Funds (Invesco Tax-Exempt Funds...   \n",
      "1   AIM Tax-Exempt Funds (Invesco Tax-Exempt Funds...   \n",
      "2               Memphis Light, Gas and Water Division   \n",
      "3                         CNB Community Bancorp, Inc.   \n",
      "4                           Oppenheimer Holdings Inc.   \n",
      "5                           Oppenheimer Holdings Inc.   \n",
      "6                           Oppenheimer Holdings Inc.   \n",
      "7                           Oppenheimer Holdings Inc.   \n",
      "8                               LKA Gold Incorporated   \n",
      "9                   Mettler-Toledo International Inc.   \n",
      "10                      Centric Financial Corporation   \n",
      "11                       American Mineral Group, Inc.   \n",
      "\n",
      "   DETAIL_JSON.parsing_status  avg_sent   sum_sent  hit_count  positive_hits  \\\n",
      "0                     WARNING  1.050844  18.915194       1607           1085   \n",
      "1                     WARNING  1.050844  18.915194       1607           1085   \n",
      "2                     WARNING  0.415304  24.918229       2828           1900   \n",
      "3                     WARNING  0.165484   5.957420       1177            693   \n",
      "4                     SUCCESS  0.804473   9.653681       1049            762   \n",
      "5                     SUCCESS  0.804473   9.653681       1049            762   \n",
      "6                     SUCCESS  0.804473   9.653681       1049            762   \n",
      "7                     SUCCESS  0.804473   9.653681       1049            762   \n",
      "8                     SUCCESS  0.591807  14.203374       1463            956   \n",
      "9                     WARNING  0.618749  25.368692       3869           2253   \n",
      "10                    WARNING  0.192458  10.585198       1429            972   \n",
      "11                    SUCCESS -0.332021  -6.308406       1544            825   \n",
      "\n",
      "    negative_hits  section_count  word_count  \n",
      "0             522             69       22507  \n",
      "1             522             69       22507  \n",
      "2             928            152       35714  \n",
      "3             484             91       14343  \n",
      "4             287             48        9550  \n",
      "5             287             48        9550  \n",
      "6             287             48        9550  \n",
      "7             287             48        9550  \n",
      "8             507             73       19169  \n",
      "9            1616             91       43802  \n",
      "10            457             79       17672  \n",
      "11            719             98       21894  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ndjson\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "# folder with the Reference, Data, Word Count, and Sentiment zipped files\n",
    "os.chdir('F:\\\\sample')\n",
    "\n",
    "\n",
    "#### Filing Reference Package ####\n",
    "# create an empty list, combined_ref, and loop through each file and combine to combined_ref\n",
    "# combined ref will be a list of dictionaries\n",
    "combined_ref = []\n",
    "for file in os.listdir():\n",
    "    if(fnmatch.fnmatch(file, 'SP_FILING_REFERENCE*')):\n",
    "        with open(file,'r',encoding='utf_8') as ref:\n",
    "            ref = ndjson.load(ref)\n",
    "        combined_ref.extend(ref)    \n",
    " \n",
    "# normalize the reference package from its NDJSON form into a Data Frame - uses from pandas.io.json import json_normalize\n",
    "ref_normalize = pd.json_normalize(combined_ref)\n",
    "\n",
    "# change order of columns to reflect User Guide documentation\n",
    "ref_normalize = ref_normalize[['ID', 'DOCUMENT_ID','DOCUMENT_TYPE','FILING_DATE','MODIFIED_AT','DETAIL_JSON.company_name', 'DETAIL_JSON.parsing_status']]\n",
    "\n",
    "# convert the ID and document ID field to a string\n",
    "ref_normalize['ID'] = ref_normalize['ID'].apply(str)\n",
    "ref_normalize['DOCUMENT_ID'] = ref_normalize['DOCUMENT_ID'].apply(str)\n",
    "# ref_normalize['DETAIL_JSON.ISIN_active'] = ref_normalize['DETAIL_JSON.ISIN_active'].apply(str)\n",
    "# ref_normalize['DETAIL_JSON.SP_DocumentId'] = ref_normalize['DETAIL_JSON.SP_DocumentId'].apply(str)\n",
    "\n",
    "#### Sentiment Score Package ####\n",
    "# create an empty list, combined_sc, and loop through each file and combine to combined_sc\n",
    "# combined_sc will be a list of dictionaries\n",
    "combined_sc = []\n",
    "for file in os.listdir():\n",
    "    if(fnmatch.fnmatch(file, 'SP_FILING_SENTIMENT*')):\n",
    "        with open(file,'r',encoding='utf_8') as sc:# gzip 用来打开压缩文件中的数据\n",
    "            sc = ndjson.load(sc)\n",
    "        combined_sc.extend(sc)  # 加入最后\n",
    "\n",
    "\n",
    "## Filing Level Function\n",
    "# Function for calculating the sentiment figures at the main filing level - i.e., the aggregated sentiment figures for the actual\n",
    "# filing (EXCLUDING exhibits)\n",
    "#Parameter: filing_type - the filing type of the data in combined_sc (examples: '10-k', '10-q')\n",
    "def filing_level_func(filing_type):\n",
    "# column names of sentiment scores package based on User Guide documentation\n",
    "    column_names = ['ID','avg_sent','sum_sent','hit_count','positive_hits','negative_hits','section_count','word_count']\n",
    "# create empty list called filin g_level_list\n",
    "    filing_level_list = [[]]\n",
    "# loop through each element in combined_sc, check if the filing_type key exists in the 'SENTIMENT' key\n",
    "# if it does append doc_level_list with ID and the sentiment scores\n",
    "# if it does not, append doc_level_level with ID and NAs\n",
    "    for element in range(len(combined_sc)):\n",
    "        if combined_sc[element].get('SENTIMENT',{}).get(filing_type):\n",
    "            filing_level_list.append([str(combined_sc[element]['ID']), \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['avg_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['sum_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['hit_count'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['positive_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['negative_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['section_count'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['word_count']])\n",
    "        else:\n",
    "            filing_level_list.append([str(combined_sc[element]['ID']), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,np.nan])\n",
    "\n",
    "    # take contents of filing_level_list and put into a data frame called filing_level_df\n",
    "    filing_level_df = pd.DataFrame(filing_level_list[1:len(filing_level_list)], columns = column_names)    \n",
    "     \n",
    "    # convert the ID field to a string\n",
    "    filing_level_df['ID'] = filing_level_df['ID'].apply(str)\n",
    "    \n",
    "    # return the data frame\n",
    "    return filing_level_df\n",
    "\n",
    "\n",
    "## Section Level Function\n",
    "# Function for calculating the sentiment figures at the section level\n",
    "#Parameter: \n",
    "# filing_type - the filing type of the data in combined_sc (examples: 'AR', 'QR', 'SR')\n",
    "# section - the section of the filing_type of the data in combined_sc (examples: 'data', 'letter to shareholders', 'ceo report',etc)    \n",
    "def section_level_func(filing_type, section):\n",
    "# column names of sentiment scores package based on User Guide documentation\n",
    "    column_names = ['ID','avg_sent','sum_sent','hit_count','positive_hits','negative_hits','section_count','word_count']   \n",
    "# create empty list called section_level_list\n",
    "    section_level_list = [[]] \n",
    "# loop through each element in combined_sc, check if the section key exists in the 'SENTIMENT' key -> filing_type key\n",
    "# if it does append section_level_list with ID and the sentiment scores\n",
    "# if it does not, append section_level_level with ID and NAs\n",
    "    for element in range(len(combined_sc)):\n",
    "        if combined_sc[element].get('SENTIMENT',{}).get(filing_type,{}).get(section):\n",
    "            section_level_list.append([str(combined_sc[element]['ID']), \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['avg_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['sum_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['hit_count'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['positive_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['negative_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['section_count'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['word_count']])\n",
    "        else:\n",
    "            section_level_list.append([str(combined_sc[element]['ID']), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,np.nan])\n",
    "\n",
    "    # take contents of section_level_list and put into a data frame called section_level_df\n",
    "    section_level_df = pd.DataFrame(section_level_list[1:len(section_level_list)], columns = column_names)    \n",
    "    \n",
    "    # convert the ID field to a string\n",
    "    section_level_df['ID'] = section_level_df['ID'].apply(str)\n",
    "    \n",
    "    # return the data frame\n",
    "    return section_level_df\n",
    "\n",
    "\n",
    "## Sub-section Level Function  \n",
    "#Parameter: \n",
    "# filing_type - the filing type of the data in combined_sc (examples: '10-k', '10-q')\n",
    "# section - the section of the filing_type of the data in combined_sc (examples: 'data', 'letter to shareholders', 'ceo report',etc)    \n",
    "# sub-section - the sub-section of the section of the filing_type in combined_sc (examples: 'data','esg','risk', etc.)  \n",
    "def sub_level_func(filing_type, section, sub):\n",
    "# column names of sentiment scores package based on User Guide documentation\n",
    "    column_names = ['ID','avg_sent','sum_sent','hit_count','positive_hits','negative_hits','section_count','word_count']\n",
    "# create empty list called sub_level_list\n",
    "    sub_level_list = [[]] \n",
    "# loop through each element in combined_sc, check if the seub-section key exists in the 'SENTIMENT' key -> filing_type key -> section key\n",
    "# if it does append sub_level_list with ID and the sentiment scores\n",
    "# if it does not, append sub_level_list with ID and NAs\n",
    "    for element in range(len(combined_sc)):\n",
    "        if combined_sc[element].get('SENTIMENT',{}).get(filing_type,{}).get(section,{}).get(sub):\n",
    "            sub_level_list.append([str(combined_sc[element]['ID']), \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['avg_sent'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['sum_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['hit_count'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['positive_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['negative_hits'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['section_count'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['word_count']])\n",
    "      \n",
    "        else: sub_level_list.append([str(combined_sc[element]['ID']), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,np.nan])\n",
    "        \n",
    "    # take contents of sub_level_list and put into a data frame called sub_level_df\n",
    "    sub_level_df = pd.DataFrame(sub_level_list[1:len(sub_level_list)], columns = column_names)    \n",
    "    \n",
    "    # convert the ID field to a string\n",
    "    sub_level_df['ID'] = sub_level_df['ID'].apply(str)\n",
    "    \n",
    "    # return the data frame\n",
    "    return sub_level_df\n",
    "\n",
    "## Examples of calling functions\n",
    "# get the AR sentiment data at the filing level\n",
    "ars = filing_level_func('ar')\n",
    "\n",
    "# Join reference information with sentiment metrics\n",
    "combined = pd.merge(left = ref_normalize, right = ars, on = 'ID')\n",
    "\n",
    "print(combined)\n",
    "\n",
    "# combined.groupy({})\n",
    "# type(combined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3e1d988fd02f3af9046135819fd37ed5d41f46c7de55723b70daeaf254c35f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
